{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efad38a-c54f-4f20-bccc-46f633b0b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Sentiment_df[\"Subjectivity\"], Sentiment_df[\"Polarity\"], \"o\")\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "plt.gca().spines[\"left\"].set_position((\"data\", Sentiment_df[\"Subjectivity\"].mean()))\n",
    "plt.gca().spines[\"bottom\"].set_position((\"data\", Sentiment_df[\"Polarity\"].mean()))\n",
    "\n",
    "\n",
    "def get_lims(Sentiment_df, column, w=0.1):\n",
    "    mean = Sentiment_df[column].mean()\n",
    "    max_diff = max(\n",
    "        abs(Sentiment_df[column].max() - mean),\n",
    "        abs(Sentiment_df[column].min() - mean),\n",
    "    )\n",
    "    return [mean - max_diff - max_diff * w, mean + max_diff + max_diff * w]\n",
    "\n",
    "\n",
    "plt.xlim(get_lims(Sentiment_df, \"Subjectivity\"))\n",
    "plt.ylim(get_lims(Sentiment_df, \"Polarity\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d164ebf-24d2-497a-9a34-d85c232343c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff418c0-9a39-4376-b89a-19b1fd52993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Longer needed\n",
    "\n",
    "# data =api_response.json()\n",
    "# articles = data.get(\"articles\",[])\n",
    "\n",
    "# from textblob.classifiers import NaiveBayesClassifier\n",
    "# stories = api_response.stories\n",
    "# for story in stories:\n",
    "#     headline = story.title\n",
    "#     body_text = story.body\n",
    "#     combined_text = headline + \" \" + body_text\n",
    "# Use TextBlob to perform sentiment analysis\n",
    "# Sentiment ranges -1 to 1 for polarity where -1 is negative, 0 is neutral, and 1 is positive\n",
    "# Second value returned is sentiment subjectivity range of 0 to 1 where 0 is objective and 1 represents subjective\n",
    "    # sentiment = TextBlob(combined_text)\n",
    "    # print(sentiment.sentiment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4007feef-c055-43c2-b586-eeeb5a85df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping Code For Reference\n",
    "\n",
    "# stories = api_response.stories\n",
    "# for story in stories:\n",
    "#     headline = story.title\n",
    "#     body_text = story.body\n",
    "#     combined_text = headline + \" \" + body_text\n",
    "\n",
    "#     sentiment = TextBlob(combined_text)\n",
    "#     data = [(sentence, sentence.sentiment.polarity) for sentence in sentiment.sentences]\n",
    "#     Sentiment_df = pd.DataFrame(data, columns=['sentence', 'polarity'])\n",
    "#     Sentiment_df\n",
    "#     print(sentiment.sentiment)\n",
    "#     type(sentiment.sentiment)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9e9192-d322-4c5d-972d-5bd7b7f1b9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "# Define the named tuple\n",
    "MyTuple = namedtuple('MyTuple', ['polarity', 'subjectivity'])\n",
    "\n",
    "# Define the list of named tuples with both polarity and subjectivity values\n",
    "my_list = [MyTuple(polarity=sentiment.sentiment, subjectivity=sentiment.sentiment), MyTuple(polarity=sentiment.sentiment, subjectivity=sentiment.sentiment)]\n",
    "\n",
    "# Convert the list of named tuples to a list of dictionaries\n",
    "my_dict_list = [x._asdict() for x in my_list]\n",
    "\n",
    "# Create the pandas DataFrame\n",
    "Sentiment_df = pd.DataFrame(my_dict_list)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(Sentiment_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a008563-f987-4bb5-b191-e732d670ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HistogramsParams.Builder histogramsBuilder = HistogramsParams\n",
    "                .newBuilder();\n",
    "\n",
    "        # histogramsBuilder.setId(id);\n",
    "        # histogramsBuilder.setNotId(notId);\n",
    "        # histogramsBuilder.setTitle(title);\n",
    "        # histogramsBuilder.setBody(body);\n",
    "        # histogramsBuilder.setText(text);\n",
    "        # histogramsBuilder.setLanguage(language);\n",
    "        # histogramsBuilder.setNotLanguage(notLanguage);\n",
    "        # histogramsBuilder.setPublishedAtStart(publishedAtStart);\n",
    "        # histogramsBuilder.setPublishedAtEnd(publishedAtEnd);\n",
    "        # histogramsBuilder.setCategoriesTaxonomy(categoriesTaxonomy);\n",
    "        # histogramsBuilder.setCategoriesConfident(categoriesConfident);\n",
    "        # histogramsBuilder.setCategoriesId(categoriesId);\n",
    "        # histogramsBuilder.setNotCategoriesId(notCategoriesId);\n",
    "        # histogramsBuilder.setCategoriesLevel(categoriesLevel);\n",
    "        # histogramsBuilder.setNotCategoriesLevel(notCategoriesLevel);\n",
    "        # histogramsBuilder.setEntitiesTitleText(entitiesTitleText);\n",
    "        # histogramsBuilder.setNotEntitiesTitleText(notEntitiesTitleText);\n",
    "        # histogramsBuilder.setEntitiesTitleType(entitiesTitleType);\n",
    "        # histogramsBuilder.setNotEntitiesTitleType(notEntitiesTitleType);\n",
    "        # histogramsBuilder.setEntitiesTitleLinksDbpedia(entitiesTitleLinksDbpedia);\n",
    "        # histogramsBuilder.setNotEntitiesTitleLinksDbpedia(notEntitiesTitleLinksDbpedia);\n",
    "        # histogramsBuilder.setEntitiesBodyText(entitiesBodyText);\n",
    "        # histogramsBuilder.setNotEntitiesBodyText(notEntitiesBodyText);\n",
    "        # histogramsBuilder.setEntitiesBodyType(entitiesBodyType);\n",
    "        # histogramsBuilder.setNotEntitiesBodyType(notEntitiesBodyType);\n",
    "        # histogramsBuilder.setEntitiesBodyLinksDbpedia(entitiesBodyLinksDbpedia);\n",
    "        # histogramsBuilder.setNotEntitiesBodyLinksDbpedia(notEntitiesBodyLinksDbpedia);\n",
    "        # histogramsBuilder.setSentimentTitlePolarity(sentimentTitlePolarity);\n",
    "        # histogramsBuilder.setNotSentimentTitlePolarity(notSentimentTitlePolarity);\n",
    "        # histogramsBuilder.setSentimentBodyPolarity(sentimentBodyPolarity);\n",
    "        # histogramsBuilder.setNotSentimentBodyPolarity(notSentimentBodyPolarity);\n",
    "        # histogramsBuilder.setMediaImagesCountMin(mediaImagesCountMin);\n",
    "        # histogramsBuilder.setMediaImagesCountMax(mediaImagesCountMax);\n",
    "        # histogramsBuilder.setMediaImagesWidthMin(mediaImagesWidthMin);\n",
    "        # histogramsBuilder.setMediaImagesWidthMax(mediaImagesWidthMax);\n",
    "        # histogramsBuilder.setMediaImagesHeightMin(mediaImagesHeightMin);\n",
    "        # histogramsBuilder.setMediaImagesHeightMax(mediaImagesHeightMax);\n",
    "        # histogramsBuilder.setMediaImagesContentLengthMin(mediaImagesContentLengthMin);\n",
    "        # histogramsBuilder.setMediaImagesContentLengthMax(mediaImagesContentLengthMax);\n",
    "        # histogramsBuilder.setMediaImagesFormat(mediaImagesFormat);\n",
    "        # histogramsBuilder.setNotMediaImagesFormat(notMediaImagesFormat);\n",
    "        # histogramsBuilder.setMediaVideosCountMin(mediaVideosCountMin);\n",
    "        # histogramsBuilder.setMediaVideosCountMax(mediaVideosCountMax);\n",
    "        # histogramsBuilder.setAuthorId(authorId);\n",
    "        # histogramsBuilder.setNotAuthorId(notAuthorId);\n",
    "        # histogramsBuilder.setAuthorName(authorName);\n",
    "        # histogramsBuilder.setNotAuthorName(notAuthorName);\n",
    "        # histogramsBuilder.setSourceId(sourceId);\n",
    "        # histogramsBuilder.setNotSourceId(notSourceId);\n",
    "        # histogramsBuilder.setSourceName(sourceName);\n",
    "        # histogramsBuilder.setNotSourceName(notSourceName);\n",
    "        # histogramsBuilder.setSourceDomain(sourceDomain);\n",
    "        # histogramsBuilder.setNotSourceDomain(notSourceDomain);\n",
    "        # histogramsBuilder.setSourceLocationsCountry(sourceLocationsCountry);\n",
    "        # histogramsBuilder.setNotSourceLocationsCountry(notSourceLocationsCountry);\n",
    "        # histogramsBuilder.setSourceLocationsState(sourceLocationsState);\n",
    "        # histogramsBuilder.setNotSourceLocationsState(notSourceLocationsState);\n",
    "        # histogramsBuilder.setSourceLocationsCity(sourceLocationsCity);\n",
    "        # histogramsBuilder.setNotSourceLocationsCity(notSourceLocationsCity);\n",
    "        # histogramsBuilder.setSourceScopesCountry(sourceScopesCountry);\n",
    "        # histogramsBuilder.setNotSourceScopesCountry(notSourceScopesCountry);\n",
    "        # histogramsBuilder.setSourceScopesState(sourceScopesState);\n",
    "        # histogramsBuilder.setNotSourceScopesState(notSourceScopesState);\n",
    "        # histogramsBuilder.setSourceScopesCity(sourceScopesCity);\n",
    "        # histogramsBuilder.setNotSourceScopesCity(notSourceScopesCity);\n",
    "        # histogramsBuilder.setSourceScopesLevel(sourceScopesLevel);\n",
    "        # histogramsBuilder.setNotSourceScopesLevel(notSourceScopesLevel);\n",
    "        # histogramsBuilder.setSourceLinksInCountMin(sourceLinksInCountMin);\n",
    "        # histogramsBuilder.setSourceLinksInCountMax(sourceLinksInCountMax);\n",
    "        # histogramsBuilder.setSourceRankingsAlexaRankMin(sourceRankingsAlexaRankMin);\n",
    "        # histogramsBuilder.setSourceRankingsAlexaRankMax(sourceRankingsAlexaRankMax);\n",
    "        # histogramsBuilder.setSourceRankingsAlexaCountry(sourceRankingsAlexaCountry);\n",
    "        # histogramsBuilder.setSocialSharesCountFacebookMin(socialSharesCountFacebookMin);\n",
    "        # histogramsBuilder.setSocialSharesCountFacebookMax(socialSharesCountFacebookMax);\n",
    "        # histogramsBuilder.setSocialSharesCountGooglePlusMin(socialSharesCountGooglePlusMin);\n",
    "        # histogramsBuilder.setSocialSharesCountGooglePlusMax(socialSharesCountGooglePlusMax);\n",
    "        # histogramsBuilder.setSocialSharesCountLinkedinMin(socialSharesCountLinkedinMin);\n",
    "        # histogramsBuilder.setSocialSharesCountLinkedinMax(socialSharesCountLinkedinMax);\n",
    "        # histogramsBuilder.setSocialSharesCountRedditMin(socialSharesCountRedditMin);\n",
    "        # histogramsBuilder.setSocialSharesCountRedditMax(socialSharesCountRedditMax);\n",
    "        # histogramsBuilder.setIntervalStart(intervalStart);\n",
    "        # histogramsBuilder.setIntervalEnd(intervalEnd);\n",
    "        # histogramsBuilder.setIntervalWidth(intervalWidth);\n",
    "        # histogramsBuilder.setField(field);\n",
    "\n",
    "        try {Histograms result = apiInstance\n",
    "            .listHistograms(histogramsBuilder.build());\n",
    "            System.out.println(result);\n",
    "        } catch (ApiException e) {\n",
    "            System.err\n",
    "                    .println(\"Exception when calling DefaultApi#listHistograms\");\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "\n",
    "\n",
    "plt.hist(sentiment_scores, bins=10)\n",
    "plt.xlabel(\"Sentiment Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec765e0-6a97-4aff-965d-cd9bd62bfce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #Data Normalizer not going to use this \n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# scale = scaler.fit(Sentiment_df)\n",
    "# # normalize the sen_matrix\n",
    "# norm_df = pd.DataFrame(scale.transform(Sentiment_df), columns=Sentiment_df.columns)\n",
    "# norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a832f9-3540-40ad-bd22-d75539d5a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crypto_name\n",
    "\n",
    "#         if name != crypto_name:\n",
    "\n",
    "#             market_data = cg.get_coin_market_chart_by_id(id=name, vs_currency='usd', days=days)\n",
    "#             prices = [price[1] for price in market_data['prices']]\n",
    "#             dates = [dt.datetime.fromtimestamp(price[0] / 1000).date() for price in market_data['prices']]\n",
    "#             marketData_df = pd.DataFrame({'Date': dates, name.capitalize(): prices})\n",
    "#             marketData_df['Date'] = pd.to_datetime(marketData_df['Date'])\n",
    "#             marketData_df.set_index('Date', inplace=True)\n",
    "#             marketData_df = marketData_df.resample('D').last()\n",
    "    \n",
    "#     top10_marketData_dfs.append(marketData_df)\n",
    "    \n",
    "#     top10_marketData_dfs.append(crypto_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19012a69-8500-463d-9899-5e39b6c88574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(Sentiment_df)\n",
    "# Sentiment_df.hvplot(x='Polarity',y='Subjectivity',height=250, width=250, colorbar=False)\n",
    "\n",
    "# heatmaps = pn.panel({day: Sentiment_df[Sentiment_df['PublishDate'] == day].hvplot.heatmap(x='x', y='y', title=day.strftime('%Y-%m-%d')) for day in Sentiment_df['PublishDate'].unique()})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93713ee-322d-42ea-981f-e902b39f98b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four quandrant scatter plot show show sentiment vs subjectivity\n",
    "\n",
    "\n",
    "field = 'keywords'\n",
    "opts = {\n",
    "  'title': 'bitcoin',\n",
    "  'body': 'bitcoin',\n",
    "  'text': 'bitcoin',\n",
    "  'published_at_start': 'NOW-7DAYS',\n",
    "  'published_at_end': 'NOW',\n",
    "  'categories_confident': True,\n",
    "  'source_scopes_country': ['US','GB']\n",
    "  # 'language': ['language_example'],\n",
    "  # 'not_language': ['language_example'],\n",
    "  # 'categories_taxonomy': 'categories_taxonomy_example',\n",
    "  # 'sentiment_title_polarity': 'sentiment_title_polarity_example',\n",
    "  # 'sentiment_body_polarity': 'sentiment_body_polarity_example',\n",
    "  # 'not_source_scopes_country': ['source_scopes_country_example'],\n",
    "\n",
    "}\n",
    "\n",
    "try:\n",
    "    # List trends\n",
    "    api_response = api_instance.list_trends(field, **opts)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling DefaultApi->list_trends: %s\\n\" % e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0e530a-4334-4617-8731-f949e364c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "\n",
    "Keywords = []\n",
    "\n",
    "field = 'keywords'\n",
    "opts = {\n",
    "  'title': 'bitcoin',\n",
    "  'body': 'bitcoin',\n",
    "  'text': 'bitcoin',\n",
    "  'published_at_start': 'NOW-7DAYS',\n",
    "  'published_at_end': 'NOW',\n",
    "  'categories_confident': True,\n",
    "  'source_scopes_country': ['US','GB']\n",
    "}\n",
    "api_response = api_instance.list_trends(field, **opts)\n",
    "\n",
    "api_response = api_instance.list_trends(field, **opts)\n",
    "trends_dict = api_response.trends\n",
    "# # pprint(trends_dict)\n",
    "# print(trends_dict)\n",
    "\n",
    "# 'count': trend.count,\n",
    "trends_data = [{'value': trend.value} for trend in api_response.trends]\n",
    "print(trends_data)\n",
    "type(trends_data)\n",
    "# string = trends_dict.text\n",
    "    \n",
    "Trends_text = \", \".join(trends_data)\n",
    "\n",
    "# type(trends_dict)\n",
    "# wordcloud = WordCloud(width=800, height=400, max_words=100, background_color='white').generate(trends_data)    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# Keywords_df = pd.DataFrame(Keywords)\n",
    "# Keywords_df\n",
    "\n",
    "    \n",
    "    # html = api_response.text\n",
    "# wordcloud = WordCloud(width=800, height=400, max_words=100, background_color='white').generate(String)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fee6b12-4007-47e5-a0d7-8228fcd366f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_id = os.getenv('X-AYLIEN-NewsAPI-Application-ID')\n",
    "api_key = os.getenv('X-AYLIEN-NewsAPI-Application-Key')\n",
    "\n",
    "configuration = aylien_news_api.Configuration()\n",
    "configuration.api_key['X-AYLIEN-NewsAPI-Application-ID'] = api_id\n",
    "configuration.api_key['X-AYLIEN-NewsAPI-Application-Key'] = api_key\n",
    "\n",
    "# types\n",
    "# source locations country name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad69889-141c-4b80-96ff-7814b6f5ce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set Client variable\n",
    "client = aylien_news_api.ApiClient(configuration)\n",
    "api_instance = aylien_news_api.DefaultApi(client)\n",
    "\n",
    "field = 'social_shares_count.reddit'\n",
    "opts = {\n",
    "  'title': 'bitcoin',\n",
    "  'body': 'bitcoin',\n",
    "  'text': 'bitcoin',\n",
    "  'published_at_start': 'NOW-30DAYS',\n",
    "  'published_at_end': 'NOW',\n",
    "  'categories_confident': True\n",
    "}\n",
    "\n",
    "try:\n",
    "    # List histograms\n",
    "    api_response = api_instance.list_histograms(field=field,**opts)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling DefaultApi->list_histograms: %s\\n\" % e)\n",
    "field = 'source.rankings.alexa.rank.US'\n",
    "opts = {\n",
    "  'title': 'bitcoin',\n",
    "  'body': 'bitcoin',\n",
    "  'text': 'bitcoin',\n",
    "  'published_at_start': 'NOW-30DAYS',\n",
    "  'published_at_end': 'NOW',\n",
    "  'categories_confident': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47416d8-6cb0-4e83-8f6a-ce595e989612",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:    # List histograms\n",
    "    api_response = api_instance.list_histograms(field=field,**opts)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling DefaultApi->list_histograms: %s\\n\" % e)\n",
    "field = 'social_shares_count'\n",
    "opts = {\n",
    "  'title': 'bitcoin',\n",
    "  'body': 'bitcoin',\n",
    "  'text': 'bitcoin',\n",
    "  'published_at_start': 'NOW-30DAYS',\n",
    "  'published_at_end': 'NOW',\n",
    "  'categories_confident': True\n",
    "}\n",
    "\n",
    "try:\n",
    "    # List histograms\n",
    "    api_response = api_instance.list_histograms(field=field,**opts)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling DefaultApi->list_histograms: %s\\n\" % e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af813734-9c76-42c6-8b27-4400cd73bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aylienapiclient import HistogramsParams\n",
    "# from aylienapiclient.textapi import HistogramsApi\n",
    "# import aylienapiclient\n",
    "##This was Alex's original Aylien Query\n",
    "# try:\n",
    "#     api_response = api_instance.list_stories(\n",
    "#         title='bitcoin OR ethereum',\n",
    "#         published_at_start='NOW-7DAYS',\n",
    "#         published_at_end='NOW'\n",
    "#     )\n",
    "#     pprint(api_response)\n",
    "# except ApiException as e:\n",
    "#     print(\"Exception when calling DefaultApi->list_stories: %s\\n\" % e)\n",
    "# Set API Key and ID Variables and Reference to .env file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
